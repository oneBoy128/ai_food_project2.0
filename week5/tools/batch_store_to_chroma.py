import logging

from week5.tools.batch_generate_embedding import batch_generate_embedding

def batch_store_to_chroma(
    collection,  # ç¬¬ä¸€æ­¥åˆå§‹åŒ–çš„Chromaé›†åˆå¯¹è±¡
    chunks_list: list,  # ä½ çš„Documentåˆ—è¡¨ï¼ˆcreate_chunksç”Ÿæˆçš„ï¼‰
    tokenizer, model, device,
    batch_size: int = 2000  # æ¯æ‰¹å­˜å…¥æ•°é‡ï¼ˆå†…å­˜å¤Ÿå¯æ”¹2000ï¼‰
):
    """
    æ‰¹é‡å°†Embedding+ID+å…ƒæ•°æ®å­˜å…¥Chromaï¼Œæ”¯æŒæ–­ç‚¹ç»­è·‘
    :param collection: Chromaé›†åˆå¯¹è±¡
    :param chunks_list: Documentåˆ—è¡¨
    :param tokenizer/model/device: åˆå§‹åŒ–å¥½çš„æ¨¡å‹ç»„ä»¶ï¼ˆå¤ç”¨ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
    :param batch_size: æ¯æ‰¹å¤„ç†æ•°é‡
    """
    total_docs = len(chunks_list)
    total_batches = (total_docs // batch_size) + 1  # æ€»æ‰¹æ•°
    logging.info(f"å¼€å§‹å­˜å…¥Chromaï¼šå…±{total_docs}ä¸ªDocumentï¼Œåˆ†{total_batches}æ‰¹å¤„ç†")
    print(f"å¼€å§‹å­˜å…¥Chromaï¼šå…±{total_docs}ä¸ªDocumentï¼Œåˆ†{total_batches}æ‰¹å¤„ç†")

    # éå†æ¯æ‰¹æ•°æ®
    for batch_idx in range(total_batches):
        # 1. è®¡ç®—å½“å‰æ‰¹çš„èµ·æ­¢ç´¢å¼•
        start = batch_idx * batch_size
        end = min((batch_idx + 1) * batch_size, total_docs)  # æœ€åä¸€æ‰¹é¿å…è¶Šç•Œ
        current_batch = chunks_list[start:end]
        current_batch_size = len(current_batch)

        if current_batch_size == 0:
            logging.info(f"âš ï¸  ç¬¬{batch_idx+1}æ‰¹æ— æ•°æ®ï¼Œè·³è¿‡")
            continue

        try:
            # 2. è°ƒç”¨ä½ çš„å‡½æ•°ç”Ÿæˆå½“å‰æ‰¹çš„Embedding+ID+å…ƒæ•°æ®
            embeddings, doc_ids, metadatas = batch_generate_embedding(
                chunks_list=current_batch,
                tokenizer=tokenizer,
                model=model,
                device=device
            )

            doc_texts = [doc.page_content for doc in current_batch]  # å…³é”®ï¼šæå–æ¯ä¸ªDocumentçš„æ–‡æœ¬
            # 3. å­˜å…¥Chromaï¼ˆæ ¸å¿ƒAPIï¼‰
            collection.add(
                embeddings=embeddings,  # 384ç»´å‘é‡åˆ—è¡¨
                ids=doc_ids,            # å”¯ä¸€IDåˆ—è¡¨ï¼ˆRecipeId_ç´¢å¼•ï¼Œä¸é‡å¤ï¼‰
                metadatas=metadatas,    # å…ƒæ•°æ®åˆ—è¡¨ï¼ˆé£Ÿè°±ä¿¡æ¯ï¼Œç”¨äºç­›é€‰ï¼‰
                documents=doc_texts     # æ–°å¢ï¼šå­˜å…¥æ–‡æœ¬ï¼Œæ£€ç´¢æ—¶æ‰èƒ½è¿”å›
            )

            # 5. è®°å½•è¿›åº¦
            processed_docs = end  # å·²å¤„ç†çš„æ€»æ•°é‡
            progress = (processed_docs / total_docs) * 100  # è¿›åº¦ç™¾åˆ†æ¯”
            logging.info(f"âœ… ç¬¬{batch_idx+1}/{total_batches}æ‰¹å­˜å…¥æˆåŠŸï¼")
            logging.info(f"  - å¤„ç†èŒƒå›´ï¼š{start+1}-{end}/{total_docs}")
            logging.info(f"  - å½“å‰è¿›åº¦ï¼š{round(progress, 2)}%")
            logging.info(f"  - é›†åˆç´¯è®¡å‘é‡æ•°ï¼š{collection.count()}")
            print(f"ç¬¬{batch_idx+1}/{total_batches}æ‰¹å­˜å…¥æˆåŠŸï¼è¿›åº¦ï¼š{round(progress, 2)}%ï¼Œç´¯è®¡å‘é‡æ•°ï¼š{collection.count()}")

        except Exception as e:
            # å¼‚å¸¸æ•è·ï¼šæŸæ‰¹å‡ºé”™ä¸ä¸­æ–­ï¼Œè®°å½•é”™è¯¯åç»§ç»­ä¸‹ä¸€æ‰¹
            error_msg = f"âŒ ç¬¬{batch_idx+1}æ‰¹å­˜å…¥å¤±è´¥ï¼èŒƒå›´ï¼š{start+1}-{end}ï¼Œé”™è¯¯ï¼š{str(e)}"
            logging.error(error_msg)
            print(error_msg)
            # æ‰“å°è¯¦ç»†é”™è¯¯æ ˆï¼ˆæ–¹ä¾¿å®šä½é—®é¢˜ï¼Œå¦‚IDé‡å¤ã€å‘é‡ç»´åº¦é”™ï¼‰
            import traceback
            traceback.print_exc()
            continue

    # å…¨éƒ¨å®Œæˆåè®°å½•æœ€ç»ˆçŠ¶æ€
    final_count = collection.count()
    logging.info(f"ğŸ‰ è¯¥æ‰¹æ¬¡å¤„ç†å®Œæˆï¼")
    logging.info(f"  - æ€»è¾“å…¥Documentæ•°ï¼š{total_docs}")
    logging.info(f"  - Chromaæœ€ç»ˆå‘é‡æ•°ï¼š{final_count}")
    logging.info(f"  - å­˜å…¥æˆåŠŸç‡ï¼š{round((final_count / total_docs) * 100, 2)}%")
    print(f"\nğŸ‰ è¯¥æ‰¹æ¬¡å¤„ç†å®Œæˆï¼")
    print(f"  - æ€»è¾“å…¥Documentæ•°ï¼š{total_docs}")
    print(f"  - Chromaæœ€ç»ˆå‘é‡æ•°ï¼š{final_count}")
    print(f"  - å­˜å…¥æˆåŠŸç‡ï¼š{round((final_count / total_docs) * 100, 2)}%")
