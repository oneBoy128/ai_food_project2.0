#æ ¹æ®é£Ÿæå›ç­”ç”¨æˆ·
import torch
import chromadb

from week5.code_rag.build_recipe_prompt import build_recipe_prompt
from week5.code_rag.is_food_query_final_solution import is_food_query_final_solution
from week5.code_rag.rag_retrieve import rag_retrieve
from chromadb import PersistentClient
from week5.tools.tokenizer_loader import tokenizer_loader
from week5.code_rag.parse_conditions_first import parse_conditions_first
from week5.code_rag.extract_taste_words import extract_taste_words
from week5.code_rag.is_food_list import is_food_list

db_path = '/home/wby/projects/week5/chroma_db/chroma_recipe_db'
qwen_model_path = '/home/wby/projects/model/Qwen-7B-Chat'
device = 'cuda' if torch.cuda.is_available() else 'cpu'
#è¿æ¥æ•°æ®åº“
chroma_client = PersistentClient(
    path=db_path,
    settings=chromadb.config.Settings(
        anonymized_telemetry=False,
        allow_reset=False
    )
)

#åŠ è½½qwen_7Bçš„åˆ†è¯å™¨
qwen_tokenizer = tokenizer_loader(qwen_model_path)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
collection = chroma_client.get_collection(name='recipe_50w_384d_ver2')

rag_name_lists = []
rag_lists = []

#è¿‡æ»¤å‡½æ•°ï¼Œè¿‡æ»¤å‡ºæå–çš„å“ªäº›å•è¯æ˜¯é£Ÿç‰©
def filter_list(result_list, qwen_model, qwen_tokenizer):
    print(result_list)
    final_results = []
    for result in result_list:
        if is_food_query_final_solution(result, qwen_model, qwen_tokenizer) == 'YES':
            final_results.append(result)
    return final_results

# å»é‡
def del_same(arrlist):
    seen = set()
    result = []
    for arr in arrlist:
        if arr not in seen:
            seen.add(arr)
            result.append(arr)
    return result


def rag_recipe_qa_fixed(user_query,model, tokenizer, prompt_template, top_k=3):
    """
    ä¿®å¤åçš„å®Œæ•´RAGé—®ç­”å‡½æ•°ï¼šè§£å†³è§£ç ç©ºç™½é—®é¢˜
    """
    print(f"ğŸ” æ­£åœ¨å¤„ç†æŸ¥è¯¢ï¼š{user_query}")
    # 1. æ£€ç´¢ç»“æœï¼ˆä¸å˜ï¼‰
    #æå–ä¸€å¥è¯ä¸­é£Ÿç‰©çš„å•è¯
    test_list = extract_taste_words(user_query)
    result_list = is_food_list(user_query, model, tokenizer)
    filtered_results = del_same(test_list+result_list)
    print(f"è¿‡æ»¤åçš„æ•°ç»„{filtered_results}")
    querystr = ' '.join(filtered_results)
    print(f"è¿‡æ»¤åçš„ç»“æœ{querystr}")
    retrieved_results = rag_retrieve(query=querystr, top_k=top_k)

    for i in range(len(retrieved_results)):
        rag_name_lists.append(retrieved_results[i]['meta']['Name'])
        rag_lists.append(retrieved_results[i])
    if not retrieved_results:
        return "æŠ±æ­‰ï¼Œæš‚æ—¶æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ‚¨éœ€æ±‚çš„ç¾é£Ÿ"

    # 2. æ‹¼æ¥æç¤ºè¯ï¼ˆä¸å˜ï¼‰
    final_prompt = build_recipe_prompt(
        query=user_query,
        retrieved_results=retrieved_results,
        prompt_template=prompt_template
    )
    # 3. æ¨¡å‹ç”Ÿæˆï¼šå…³é”®ä¿®æ”¹â€”â€”å¢å¤§max_new_tokensï¼Œå…³é—­æˆªæ–­
    with torch.no_grad():
        inputs = tokenizer.apply_chat_template(
            [   {'role':"system",'content':'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¨å¸ˆï¼Œå‘ç”¨æˆ·æ¨èä½ çš„é£Ÿè°±, å¹¶ä¸”ä½ èƒ½è¯¦ç»†çš„æœ‰é€»è¾‘çš„æè¿°ä½ çš„ç†ç”±'},
                {"role": "user", "content": final_prompt}
            ],
            tokenize=True,
            add_generation_prompt=True,
            return_tensors="pt"
        ).to(model.device)

        # å…³é”®ä¿®æ”¹ï¼šmax_new_tokensè®¾ä¸º800ï¼ˆè¶³å¤Ÿç”Ÿæˆå®Œæ•´æ¨èï¼‰ï¼ŒåŠ eos_token_idé¿å…æ— æ„ä¹‰ç”Ÿæˆ
        outputs = model.generate(
            inputs,
            max_new_tokens=2000,  # ä»500å¢è‡³800ï¼Œç¡®ä¿ç”Ÿæˆå®Œæ•´
            min_new_tokens=50,   # å¼ºåˆ¶ç”Ÿæˆè‡³å°‘50ä¸ªtokenï¼ˆé¿å…å¤ªçŸ­ï¼‰
            temperature=0.6,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id,  # é‡åˆ°ç»“æŸç¬¦åœæ­¢ï¼Œé¿å…å†—ä½™
            attention_mask=torch.ones_like(inputs)
        )

    # ä¿®å¤è§£ç ï¼šå³ä½¿æœ‰ç‰¹æ®Štokenï¼Œä¹Ÿå…ˆä¿ç•™åŸå§‹æ–‡æœ¬å†è¿‡æ»¤
    final_answer = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)


    print(f"\nğŸ‰ æœ€ç»ˆè¿‡æ»¤åå›ç­”ï¼š\n{final_answer}")
    print(type(final_answer))
    return final_answer if final_answer.strip() else "æ¨¡å‹å·²ç”Ÿæˆå†…å®¹ï¼Œä½†éœ€è°ƒæ•´è§£ç é€»è¾‘ï¼ˆè§åŸå§‹å†…å®¹ï¼‰"