"""
è¯¥æ¨¡å—å›ç­”æŸä¸ªå…·ä½“çš„ç¾é£Ÿåˆ¶ä½œã€‚æ¯”å¦‚how to make kung pao chicken or how to make ice creamç­‰å…·ä½“æŸç±»æˆ–æŸä¸ªé£Ÿç‰©
"""

import random
import json
import torch
from week5.code_rag.rag_retrieve import rag_retrieve

#æ„å»ºæ¨èæç¤ºè¯
prompt_template_food = """
# ç«‹å³æ‰§è¡Œï¼šç²¾å‡†æŸ¥è¯¢å¹¶è¿”å›é£Ÿè°±ä¿¡æ¯ï¼ˆç»å¯¹ç¦æ­¢å¤šä½™å†…å®¹ï¼‰
ç”¨æˆ·æŸ¥è¯¢ï¼ˆqueryï¼‰ï¼š{{query}}
ä½ çš„å”¯ä¸€ä»»åŠ¡ï¼š
1. è¾“å‡ºé€»è¾‘ï¼ˆéAå³Bï¼Œæ— ç¬¬ä¸‰ç§å¯èƒ½ï¼‰ï¼š
   - A. æ£€ç´¢ç»“æœå«ç›¸å…³é£Ÿè°±ï¼ˆå¦‚å«â€œkung pao chickenâ€ï¼‰ï¼šä»…è¾“å‡º1ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«ä¸”ä»…åŒ…å«6ä¸ªå­—æ®µï¼ˆNameã€Categoriesã€Total Timeã€Caloriesã€Ingredients and Quantitiesã€Cooking stepsï¼‰ï¼Œå­—æ®µå€¼ä¸¥æ ¼æ¥è‡ªæ£€ç´¢ç»“æœï¼Œæ— ä»»ä½•é¢å¤–æ–‡å­—ï¼›
2. å­—æ®µæ ¼å¼é“å¾‹ï¼š
   - Ingredients and Quantitiesï¼šæ¯ä¸ªé£Ÿæç”¨\\nåˆ†éš”ï¼ˆå¦‚"a:1\\nb:2"ï¼‰ï¼Œç¦æ­¢ç©ºæ ¼/é€—å·è¿æ¥ï¼›
   - Cooking stepsï¼šæ¯ä¸ªæ­¥éª¤ç”¨\\nåˆ†éš”ï¼ˆå¦‚"1. x\\n2. y"ï¼‰ï¼Œä¿ç•™åŸå§‹ç¼–å·ï¼Œç¦æ­¢åˆå¹¶æ­¥éª¤ï¼›
   - æ‰€æœ‰å­—æ®µç”¨åŒå¼•å·ï¼Œæ— ä¸­æ–‡ï¼Œæ— å¤šä½™ç¬¦å·ï¼ˆå¦‚æ¢è¡Œã€ç©ºæ ¼ï¼‰ï¼›
3. ç»ˆæç¦ä»¤ï¼š
   - ç»å¯¹ä¸å…è®¸åŒæ—¶è¾“å‡ºAå’ŒBï¼›
   - ç»å¯¹ä¸å…è®¸è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼ˆå¦‚â€œThe query did not return...â€ï¼‰ï¼›
   - ç»å¯¹ä¸å…è®¸é‡å¤å­—æ®µæˆ–æ­¥éª¤ã€‚

### å¯ç”¨çš„RAGæ£€ç´¢ç»“æœï¼ˆä»…åŸºäºæ­¤ç”Ÿæˆï¼‰
{{retrieved_results}}

### è¾“å‡ºæ ¼å¼ï¼ˆä»…ä»¥ä¸‹ä¸¤ç§ä¹‹ä¸€ï¼‰ï¼š
{
    "Name": "{Name}",
    "Categories": "{RecipeCategory}",
    "Total Time": "{TotalTime}",
    "Calories": "{Calories}",
    "Ingredients and Quantities": "ingredient1:amount\\ningredient2:amount\\n...",
    "Cooking steps": "1. Step 1\\n2. Step 2\\n...\\nN. Step N"
}
"""

# å›ç­”å…·ä½“èœè°±
def final_about_food(user_query, model, tokenizer):
    """
    ä¿®å¤åçš„å®Œæ•´RAGé—®ç­”å‡½æ•°ï¼šè§£å†³è§£ç ç©ºç™½é—®é¢˜
    """
    print(f"ğŸ” æ­£åœ¨å¤„ç†æŸ¥è¯¢ï¼š{user_query}")
    # 2. RAGæ£€ç´¢ï¼ˆå¤„ç†ç©ºç»“æœï¼‰
    rags_list = rag_retrieve(user_query, 1)
    rags_list = rags_list if rags_list else []  # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
    rags_list_str = json.dumps(rags_list, ensure_ascii=False, indent=2) #è½¬ä¸ºå­—ç¬¦ä¸²


    # 4. å¡«å……prompt
    prompt_food = prompt_template_food.replace("{{retrieved_results}}", rags_list_str).replace("{{query}}", user_query)

    # 5. æ¨¡å‹ç”Ÿæˆï¼ˆä¼˜åŒ–å‚æ•°ï¼šæå‡ç¨³å®šæ€§ï¼‰
    with torch.no_grad():
        inputs = tokenizer.apply_chat_template(
            [
                {'role': "system", 'content': 'ä½ æ˜¯ä¸“ä¸šå¨å¸ˆï¼Œä¸¥æ ¼æŒ‰JSONæ ¼å¼æ¨èé£Ÿè°±ï¼Œå›ç­”å¥½è¿™ä¸ªç¾é£Ÿæ€ä¹ˆåš'},
                {"role": "user", "content": prompt_food}
            ],
            tokenize=True,
            add_generation_prompt=True,
            return_tensors="pt",
            truncation=True,  # å¼€å¯æˆªæ–­ï¼ˆé¿å…è¾“å…¥è¿‡é•¿æŠ¥é”™ï¼‰
            max_length=4096   # é€‚é…é•¿RAGç»“æœ
        ).to(model.device)

        outputs = model.generate(
            inputs,
            max_new_tokens=1000,
            min_new_tokens=20,  # ç¡®ä¿ç”Ÿæˆè¶³å¤Ÿå†…å®¹
            temperature=0.7,     # é€‚åº¦éšæœºæ€§ï¼Œå…¼é¡¾è‡ªç„¶å’Œå‡†ç¡®
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id,
            attention_mask=torch.ones_like(inputs),
            repetition_penalty=1.2  # å‡å°‘é‡å¤å†…å®¹
        )

    # 6. è§£ç +æ ¼å¼ä¿®å¤ï¼ˆå…³é”®ï¼šå¤„ç†JSONæ ¼å¼é”™è¯¯ï¼‰
    final_answer = tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True)

    print(f"âœ… ç»“æœå®Œæˆ")
    return final_answer